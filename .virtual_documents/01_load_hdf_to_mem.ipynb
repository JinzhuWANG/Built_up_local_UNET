import h5py
import pandas as pd
import numpy as np
import geopandas as gpd
import matplotlib.pyplot as plt

from glob import glob
from tqdm.auto import tqdm

import shutil, os





# read shp file
China_shp = gpd.read_file('./data_cache/SHP/qu-sheng_dissolved.shp')
China_shp





# get all HDF files
hdf_path = r'N:/LUF-Modelling/LUTO2_JZ/Built_map/hdf'
hdf_files = glob(f"{hdf_path}/*.hdf")

# get the target files
target_files = [i for i in hdf_files if (("xinan" in i) and (('2017' in i) or ('1990_2020' in i)))]





# copy file to local disk
for f in tqdm(target_files):
    if os.path.basename(f) in [os.path.basename(f) for f in glob('./data_cache/*')]:
        print(f"{os.path.basename(f):<50} will use cached file")
        continue
        
    print( f"copying {os.path.basename(f):<50} to cache directory")
    shutil.copyfile(f,f"./data_cache/{os.path.basename(f)}")

# locate local files
local_files = sorted(glob('./data_cache/*.hdf'))
local_files











ds = h5py.File(f"{local_files[-1]}",'r')
ds = ds[list(ds.keys())[0]]
ds_arr = ds[...]

















arries = []
for hdf in local_files:
    ds = h5py.File(f"{local_files[0]}",'r')
    ds = ds[list(ds.keys())[0]]
    for d in range(ds.shape[0]):
        ds_arr = ds[d,:,:]
        break
        arries.append(ds_arr)
        ds.close()

    break





ds.shape





a1 = np.array([1,2]).reshape(-1)
a2 = np.array([3,4]).reshape(-1)


np.stack([a1,a2])


















